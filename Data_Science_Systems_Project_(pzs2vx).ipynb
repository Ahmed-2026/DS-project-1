{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMvHhfHwZv07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "382d1b70-92e2-4693-8c51-103464563993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "import sqlite3\n",
        "from io import StringIO\n",
        "import os\n",
        "\n",
        "# Install necessary packages\n",
        "!pip install pandas requests\n",
        "\n",
        "# CSV data source: https://www.kaggle.com/datasets/berkanoztas/synthetic-transaction-monitoring-dataset-aml\n",
        "# Download the SAML-D.csv file from the above link and upload it to your Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking working directory to see if the file was uploaded correctly\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "print(\"Files in the current directory:\", os.listdir())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6SOH8_8MH6Q",
        "outputId": "41c994fe-088e-44b8-af23-740897530527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n",
            "Files in the current directory: ['.config', 'test', 'SAML-D.csv', '.ipynb_checkpoints', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_data(source, file_path=None):\n",
        "    \"\"\"\n",
        "    Fetch data from either a CSV file or an API\n",
        "    \"\"\"\n",
        "    if source == 'csv':\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"Error: The file {file_path} does not exist.\")\n",
        "            return None\n",
        "        try:\n",
        "            df = pd.read_csv(file_path)\n",
        "            print(f\"Successfully read CSV file from {file_path}\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred while reading the file: {e}\")\n",
        "            return None\n",
        "    elif source == 'api':\n",
        "        API_KEY = \"ffbc68e4-95fa-41a6-ae12-92538acdb860\"\n",
        "        BASE_URL = \"https://api.coincap.io/v2\"\n",
        "        headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
        "        url = f\"{BASE_URL}/assets\"\n",
        "        try:\n",
        "            response = requests.get(url, headers=headers)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()[\"data\"]\n",
        "            print(\"Successfully fetched data from CoinCap API\")\n",
        "            return pd.DataFrame(data)\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"Error fetching data from API: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        raise ValueError(\"Invalid source. Choose 'csv' or 'api'.\")\n",
        "\n",
        "def convert_format(df, output_format):\n",
        "    \"\"\"\n",
        "    Convert DataFrame to specified output format\n",
        "    \"\"\"\n",
        "    if output_format == 'json':\n",
        "        return df.to_json(orient='records')\n",
        "    elif output_format == 'csv':\n",
        "        return df.to_csv(index=False)\n",
        "    elif output_format == 'sql':\n",
        "        return df\n",
        "    else:\n",
        "        raise ValueError(\"Invalid output format. Choose 'json', 'csv', or 'sql'.\")\n",
        "\n",
        "def modify_columns(df, columns_to_keep=None, columns_to_add=None):\n",
        "    \"\"\"\n",
        "    Modify DataFrame columns based on user input\n",
        "    \"\"\"\n",
        "    if columns_to_keep:\n",
        "        df = df[columns_to_keep]\n",
        "    if columns_to_add:\n",
        "        df = df.assign(**columns_to_add)\n",
        "    return df\n",
        "\n",
        "def store_data(data, output_format, filename=None, table_name=None):\n",
        "    \"\"\"\n",
        "    Store data in specified format (file or SQL database)\n",
        "    \"\"\"\n",
        "    if output_format in ['json', 'csv']:\n",
        "        with open(filename, 'w') as f:\n",
        "            f.write(data)\n",
        "        print(f\"Data stored in {filename}\")\n",
        "    elif output_format == 'sql':\n",
        "        with sqlite3.connect('output.db') as conn:\n",
        "            data.to_sql(table_name, conn, if_exists='replace', index=False)\n",
        "        print(f\"Data stored in SQLite database 'output.db', table '{table_name}'\")\n",
        "\n",
        "def generate_summary(df, stage):\n",
        "    \"\"\"\n",
        "    Generate and print summary of the data\n",
        "    \"\"\"\n",
        "    print(f\"\\n{stage} Summary:\")\n",
        "    print(f\"Number of records: {len(df)}\")\n",
        "    print(f\"Number of columns: {len(df.columns)}\")"
      ],
      "metadata": {
        "id": "rUtb9hMeMLn_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_input():\n",
        "    \"\"\"\n",
        "    Get user input for data source and output format\n",
        "    \"\"\"\n",
        "    source = input(\"Enter data source (csv/api): \").lower()\n",
        "    file_path = None\n",
        "    if source == 'csv':\n",
        "        file_path = input(\"Enter the filename of your CSV file (e.g., 'SAML-D.csv'): \")\n",
        "        file_path = f\"/content/{file_path}\"  # Adjust path for Colab\n",
        "    output_format = input(\"Enter output format (json/csv/sql): \").lower()\n",
        "    return source, file_path, output_format\n",
        "\n",
        "def get_column_modifications():\n",
        "    \"\"\"\n",
        "    Get user input for column modifications\n",
        "    \"\"\"\n",
        "    columns_to_keep = input(\"Enter columns to keep (comma-separated, leave blank for all): \").split(',') if input(\"Do you want to keep specific columns? (y/n): \").lower() == 'y' else None\n",
        "    columns_to_add = {col: input(f\"Enter value for new column '{col}': \") for col in input(\"Enter new columns to add (comma-separated, leave blank for none): \").split(',') if col}\n",
        "    return columns_to_keep, columns_to_add"
      ],
      "metadata": {
        "id": "4I2ESrY9MOZo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the ETL pipeline\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Get user input\n",
        "        source, file_path, output_format = get_user_input()\n",
        "\n",
        "        # Fetch data\n",
        "        df = fetch_data(source, file_path)\n",
        "        if df is None:\n",
        "            raise ValueError(\"Failed to fetch data\")\n",
        "\n",
        "        # Generate pre-processing summary\n",
        "        generate_summary(df, \"Pre-processing\")\n",
        "\n",
        "        # Modify columns\n",
        "        columns_to_keep, columns_to_add = get_column_modifications()\n",
        "        df = modify_columns(df, columns_to_keep, columns_to_add)\n",
        "\n",
        "        # Convert format\n",
        "        converted_data = convert_format(df, output_format)\n",
        "\n",
        "        # Store data\n",
        "        if output_format in ['json', 'csv']:\n",
        "            filename = f\"/content/{input('Enter output filename: ')}\"\n",
        "            store_data(converted_data, output_format, filename)\n",
        "        elif output_format == 'sql':\n",
        "            table_name = input(\"Enter SQL table name: \")\n",
        "            store_data(df, output_format, table_name=table_name)\n",
        "\n",
        "        # Generate post-processing summary\n",
        "        generate_summary(df, \"Post-processing\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "3d-w2eWoMQka"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
