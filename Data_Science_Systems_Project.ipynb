{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+HeIuyOd6x4gVCfpdlPCJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmed-2026/DS-project-1/blob/main/Data_Science_Systems_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMvHhfHwZv07",
        "outputId": "209a364c-f726-476d-cdf3-208f48734114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "import sqlite3\n",
        "import os\n",
        "from datetime import datetime\n",
        "!pip install pandas requests\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fetch a link for an online csv dataset and then retrieve it\n",
        "def fetch_csv(url):\n",
        "    response = requests.get('https://www.kaggle.com/code/yashnarendrajadhav/anti-money-laundering-transactions-project/input')\n",
        "    with open('data.csv', 'wb') as file:\n",
        "      file.write(response.content)\n",
        "    return pd.read_csv('SAML-D.csv')\n"
      ],
      "metadata": {
        "id": "NblKINN7fY1O"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#convert csv to json\n",
        "import csv\n",
        "import json\n",
        "import os\n",
        "def convert_to_json(csv_file, json_file):\n",
        "    json_data = {}\n",
        "    with open(csv_file, encoding = 'utf-8') as csv_file_handler:\n",
        "        csv_reader = csv.DictReader(csv_file_handler)\n",
        "\n",
        "        for rows in csv_reader:\n",
        "            key = rows['Time']\n",
        "            json_data[key] = rows\n",
        "    with open(json_file, 'w', encoding = 'utf-8') as json_file_handler:\n",
        "        json_file_handler.write(json.dumps(json_data, indent=4))\n",
        "\n",
        "csv_file_path = r'SAML-D.csv'\n",
        "json_file_path = r'SAML-D.json'\n",
        "convert_to_json(csv_file_path,json_file_path)"
      ],
      "metadata": {
        "id": "-5pNTMjP8CbH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vB4JRn4T8-aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#API Call\n",
        "\n",
        "API_KEY = \"ccaec122-420f-42de-8119-4e0d7ac35c01\"\n",
        "BASE_URL = \"api.coincap.io/v2\"\n",
        "\n",
        "def fetch_crypto_api(endpoints = \"/assets\", params = None):\n",
        "  headers = {\"Authorization\":f\"Bearer {API_KEY}\"}\n",
        "  url = f\"{BASE_URL}{endpoints}\"\n",
        "\n",
        "  try:\n",
        "      response = requests.get(url, headers = headers, params = params)\n",
        "      response.raise_for_status()\n",
        "      data = response.json()[\"data\"]\n",
        "  except requests.exceptions.RequestException as e:\n",
        "      print(f\"Error fetching data from API: {e}\")\n",
        "      return None"
      ],
      "metadata": {
        "id": "So1LSo2ItRdB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting API Json to DataFrames\n",
        "\n",
        "def api_data_to_df(api_data):\n",
        "  if 'data' in api_data:\n",
        "    df = pd.DataFrame(api_data['data'])\n",
        "    return df\n",
        "  else:\n",
        "    print(\"No data found in the API response.\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "cd8N9U9Sj3QP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#modifying and cleaning the data\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "def mod_data(df, removed_columns = ['Is_laundering'], add_timestamp = False):\n",
        "  if removed_columns:\n",
        "    df = df.drop(columns = removed_columns)\n",
        "  if add_timestamp:\n",
        "    df['timestamp'] = datetime.now()\n",
        "  return df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "7llti3R6g7Tb",
        "outputId": "5238fbe8-600d-4296-ab54-bd6c5759631c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0d6257f9d856>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fetch a link for an online csv dataset and then retrieve it\n",
        "def fetch_csv(url):\n",
        "    response = requests.get('https://www.kaggle.com/code/yashnarendrajadhav/anti-money-laundering-transactions-project/input')\n",
        "    with open('data.csv', 'wb') as file:\n",
        "      file.write(response.content)\n",
        "    return pd.read_csv('SAML-D.csv')\n",
        "\n",
        "#convert csv to json\n",
        "import csv\n",
        "import json\n",
        "import os\n",
        "def convert_to_json(csv_file, json_file):\n",
        "    json_data = {}\n",
        "    with open(csv_file, encoding = 'utf-8') as csv_file_handler:\n",
        "        csv_reader = csv.DictReader(csv_file_handler)\n",
        "\n",
        "        for rows in csv_reader:\n",
        "            key = rows['Time']\n",
        "            json_data[key] = rows\n",
        "    with open(json_file, 'w', encoding = 'utf-8') as json_file_handler:\n",
        "        json_file_handler.write(json.dumps(json_data, indent=4))\n",
        "\n",
        "csv_file_path = r'SAML-D.csv'\n",
        "json_file_path = r'SAML-D.json'\n",
        "convert_to_json(csv_file_path,json_file_path)\n",
        "\n",
        "#API Call\n",
        "\n",
        "API_KEY = \"ccaec122-420f-42de-8119-4e0d7ac35c01\"\n",
        "BASE_URL = \"api.coincap.io/v2\"\n",
        "\n",
        "def fetch_crypto_api(endpoints = \"/assets\", params = None):\n",
        "  headers = {\"Authorization\":f\"Bearer {API_KEY}\"}\n",
        "  url = f\"{BASE_URL}{endpoints}\"\n",
        "\n",
        "  try:\n",
        "      response = requests.get(url, headers = headers, params = params)\n",
        "      response.raise_for_status()\n",
        "      data = response.json()[\"data\"]\n",
        "  except requests.exceptions.RequestException as e:\n",
        "      print(f\"Error fetching data from API: {e}\")\n",
        "      return None\n",
        "\n",
        "#converting API Json to DataFrames\n",
        "\n",
        "def api_data_to_df(api_data):\n",
        "  if 'data' in api_data:\n",
        "    df = pd.DataFrame(api_data['data'])\n",
        "    return df\n",
        "  else:\n",
        "    print(\"No data found in the API response.\")\n",
        "    return None\n",
        "\n",
        "\n",
        "#modifying and cleaning the data\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "def mod_data(df, removed_columns = ['Is_laundering'], add_timestamp = False):\n",
        "  if removed_columns:\n",
        "    df = df.drop(columns = removed_columns)\n",
        "  if add_timestamp:\n",
        "    df['timestamp'] = datetime.now()\n",
        "  return df\n",
        "\n",
        "#ETL pipeline\n",
        "def etl_pipeline(input_file,input_format,output_format):\n",
        "  if input_format == 'csv':\n",
        "    df = fetch_csv(input_file)\n",
        "  elif input_format == 'json':\n",
        "    df = pd.read_json(input_file)\n",
        "  else:\n",
        "      raise ValueError(\"Unsupported input format\")\n",
        "  if output_format == 'csv':\n",
        "    df.to_csv('output.csv', index = False)\n",
        "  if output_format == 'json':\n",
        "    df.to_json('output.json', orient = 'records')\n",
        "  if output_format == 'sql':\n",
        "    if db_name and table_name:\n",
        "      save_as_sql(mod_df, db_name, table_name)\n",
        "    else:\n",
        "      raise ValueError(\"To save as SQL, db_name and table_name must be provided.\")\n",
        "  else:\n",
        "    raise ValueError(\"Unsupported output format\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZFJIN_naBpVs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}